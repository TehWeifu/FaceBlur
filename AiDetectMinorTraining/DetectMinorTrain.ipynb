{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-05-24T14:13:21.835068Z",
     "start_time": "2024-05-24T14:13:17.301662Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras.applications import MobileNetV2\n",
    "from keras.src.utils import image_dataset_from_directory\n",
    "from matplotlib.ticker import MultipleLocator\n",
    "from statsmodels.stats.proportion import proportion_confint\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D, Dense, Input, BatchNormalization\n",
    "from tensorflow.keras.metrics import TruePositives, TrueNegatives, FalsePositives, FalseNegatives\n",
    "from tensorflow.keras.models import Sequential, Model"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-24T14:13:21.839148Z",
     "start_time": "2024-05-24T14:13:21.836597Z"
    }
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": 2,
   "source": [
    "RANDOM_SEED = 2_055\n",
    "IMG_SIZE = (200, 200, 3)\n",
    "BATCH_SIZE = 32\n",
    "AUTOTUNE = tf.data.AUTOTUNE"
   ],
   "id": "5aefc0b55e4b78ed"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def compile_fit_model(train, validation, learning_rate: float, batch_size: int,\n",
    "                      batch_normalization: False) -> Sequential:\n",
    "    model = Sequential()\n",
    "\n",
    "    # First convolutional block\n",
    "    model.add(Input(shape=IMG_SIZE))\n",
    "    model.add(Conv2D(filters=32, kernel_size=(3, 3), activation='relu', padding='same'))\n",
    "    if batch_normalization:\n",
    "        model.add(BatchNormalization())\n",
    "    model.add(Conv2D(filters=32, kernel_size=(3, 3), activation='relu', padding='same'))\n",
    "    if batch_normalization:\n",
    "        model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    # Second convolutional block\n",
    "    model.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu', padding='same'))\n",
    "    if batch_normalization:\n",
    "        model.add(BatchNormalization())\n",
    "    model.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu', padding='same'))\n",
    "    if batch_normalization:\n",
    "        model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    # Third convolutional block\n",
    "    model.add(Conv2D(filters=128, kernel_size=(3, 3), activation='relu', padding='same'))\n",
    "    if batch_normalization:\n",
    "        model.add(BatchNormalization())\n",
    "    model.add(Conv2D(filters=128, kernel_size=(3, 3), activation='relu', padding='same'))\n",
    "    if batch_normalization:\n",
    "        model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    # Fourth convolutional block\n",
    "    model.add(Conv2D(filters=256, kernel_size=(3, 3), activation='relu', padding='same'))\n",
    "    if batch_normalization:\n",
    "        model.add(BatchNormalization())\n",
    "    model.add(Conv2D(filters=256, kernel_size=(3, 3), activation='relu', padding='same'))\n",
    "    if batch_normalization:\n",
    "        model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    # Transform convolutional block to a vector\n",
    "    model.add(GlobalAveragePooling2D())\n",
    "\n",
    "    # Dense hidden layer\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "\n",
    "    # Output layer for binary classification\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=[\n",
    "            'recall',\n",
    "            TruePositives(name='tp'),\n",
    "            TrueNegatives(name='tn'),\n",
    "            FalsePositives(name='fp'),\n",
    "            FalseNegatives(name='fn'),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    history = model.fit(train, validation_data=validation, epochs=5, batch_size=batch_size, verbose=False)\n",
    "\n",
    "    return model, history"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-24T14:13:21.848874Z",
     "start_time": "2024-05-24T14:13:21.839656Z"
    }
   },
   "id": "61372136ed333689",
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-24T14:13:21.993922Z",
     "start_time": "2024-05-24T14:13:21.849893Z"
    }
   },
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 100 files belonging to 2 classes.\n",
      "Using 80 files for training.\n",
      "Found 100 files belonging to 2 classes.\n",
      "Using 20 files for validation.\n",
      "['adult', 'minor']\n"
     ]
    }
   ],
   "execution_count": 4,
   "source": [
    "# Define paths\n",
    "base_dir = './../data/face_age_reduced'\n",
    "train_dir = base_dir\n",
    "\n",
    "train_dataset = image_dataset_from_directory(\n",
    "    base_dir,\n",
    "    validation_split=.2,\n",
    "    subset=\"training\",\n",
    "    seed=RANDOM_SEED,\n",
    "    image_size=IMG_SIZE[:2],\n",
    "    batch_size=BATCH_SIZE\n",
    ")\n",
    "\n",
    "validation_dataset = image_dataset_from_directory(\n",
    "    base_dir,\n",
    "    validation_split=.2,\n",
    "    subset=\"validation\",\n",
    "    seed=RANDOM_SEED,\n",
    "    image_size=IMG_SIZE[:2],\n",
    "    batch_size=BATCH_SIZE\n",
    ")\n",
    "\n",
    "train_ds = train_dataset.prefetch(buffer_size=AUTOTUNE)\n",
    "validation_ds = validation_dataset.prefetch(buffer_size=AUTOTUNE)\n",
    "\n",
    "# check the class names\n",
    "class_names = train_dataset.class_names\n",
    "print(class_names)"
   ],
   "id": "ef401028f2e92a6f"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Model training"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c926739adde3d0c0"
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Model 1**\n",
    "- Learning rate: 0.01\n",
    "- Batch normalization: False\n",
    "- Batch size: 32"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fb53676f3b6631c2"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "model_1, history_1 = compile_fit_model(\n",
    "    train_ds, validation_ds, learning_rate=0.01, batch_normalization=False, batch_size=32\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-24T14:13:37.626663Z",
     "start_time": "2024-05-24T14:13:21.995452Z"
    }
   },
   "id": "d0fe24fa1a0477e6",
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Model 2**\n",
    "- Learning rate: 0.005\n",
    "- Batch normalization: False\n",
    "- Batch size: 32"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "65b4975e4fd51dd"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "model_2, history_2 = compile_fit_model(\n",
    "    train_ds, validation_ds, learning_rate=0.005, batch_normalization=False, batch_size=32\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-24T14:13:49.764166Z",
     "start_time": "2024-05-24T14:13:37.627681Z"
    }
   },
   "id": "649e93526a3694be",
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Model 3**\n",
    "- Learning rate: 0.001\n",
    "- Batch normalization: False\n",
    "- Batch size: 32"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9506b007c78a623c"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "model_3, history_3 = compile_fit_model(\n",
    "    train_ds, validation_ds, learning_rate=0.001, batch_normalization=False, batch_size=32\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-24T14:14:02.642075Z",
     "start_time": "2024-05-24T14:13:49.765184Z"
    }
   },
   "id": "67029414c45c2072",
   "execution_count": 7
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Model 4**\n",
    "- Learning rate: 0.01\n",
    "- Batch normalization: True\n",
    "- Batch size: 32"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a2581e96de710435"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "model_4, history_4 = compile_fit_model(\n",
    "    train_ds, validation_ds, learning_rate=0.01, batch_normalization=True, batch_size=32\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-24T14:14:25.249645Z",
     "start_time": "2024-05-24T14:14:02.643111Z"
    }
   },
   "id": "3f2a6b33d607a5f6",
   "execution_count": 8
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Model 5**\n",
    "- Learning rate: 0.005\n",
    "- Batch normalization: True\n",
    "- Batch size: 32"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "21c7d594aa5eceee"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "model_5, history_5 = compile_fit_model(\n",
    "    train_ds, validation_ds, learning_rate=0.005, batch_normalization=True, batch_size=32\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-24T14:14:49.844940Z",
     "start_time": "2024-05-24T14:14:25.250671Z"
    }
   },
   "id": "9af3abbc811eb205",
   "execution_count": 9
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Model 6**\n",
    "- Learning rate: 0.001\n",
    "- Batch normalization: True\n",
    "- Batch size: 32"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a2aca554346bcd84"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "model_6, history_6 = compile_fit_model(\n",
    "    train_ds, validation_ds, learning_rate=0.001, batch_normalization=True, batch_size=32\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-24T14:15:12.220241Z",
     "start_time": "2024-05-24T14:14:49.845963Z"
    }
   },
   "id": "e5c9349d1c76c2fa",
   "execution_count": 10
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Model 7**\n",
    "- Learning rate: 0.01\n",
    "- Batch normalization: False\n",
    "- Batch size: 64"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "514b86ef165183a7"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "model_7, history_7 = compile_fit_model(\n",
    "    train_ds, validation_ds, learning_rate=0.01, batch_normalization=False, batch_size=64\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-24T14:15:25.978717Z",
     "start_time": "2024-05-24T14:15:12.221261Z"
    }
   },
   "id": "7f1fb40e2ea67622",
   "execution_count": 11
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Model 8**\n",
    "- Learning rate: 0.005\n",
    "- Batch normalization: False\n",
    "- Batch size: 64"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3dba819df4f81808"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "model_8, history_8 = compile_fit_model(\n",
    "    train_ds, validation_ds, learning_rate=0.005, batch_normalization=False, batch_size=64\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-24T14:15:37.806346Z",
     "start_time": "2024-05-24T14:15:25.979751Z"
    }
   },
   "id": "37e31163a37c9e46",
   "execution_count": 12
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Model 9**\n",
    "- Learning rate: 0.001\n",
    "- Batch normalization: False\n",
    "- Batch size: 64"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "72fc21320b221415"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "model_9, history_9 = compile_fit_model(\n",
    "    train_ds, validation_ds, learning_rate=0.001, batch_normalization=False, batch_size=64\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-24T14:15:50.624773Z",
     "start_time": "2024-05-24T14:15:37.807365Z"
    }
   },
   "id": "b4a224cd6a871bf8",
   "execution_count": 13
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Model 10**\n",
    "- Learning rate: 0.01\n",
    "- Batch normalization: True\n",
    "- Batch size: 64"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "773d378cf2559c86"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "model_10, history_10 = compile_fit_model(\n",
    "    train_ds, validation_ds, learning_rate=0.01, batch_normalization=True, batch_size=64\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-24T14:16:13.339011Z",
     "start_time": "2024-05-24T14:15:50.628342Z"
    }
   },
   "id": "dab87bfdf6f397ba",
   "execution_count": 14
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Model 11**\n",
    "- Learning rate: 0.005\n",
    "- Batch normalization: True\n",
    "- Batch size: 64"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c058efeefdfbe3c9"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "model_11, history_11 = compile_fit_model(\n",
    "    train_ds, validation_ds, learning_rate=0.005, batch_normalization=True, batch_size=64\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-24T14:16:36.021374Z",
     "start_time": "2024-05-24T14:16:13.340036Z"
    }
   },
   "id": "940cdcb88d477b58",
   "execution_count": 15
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Model 12**\n",
    "- Learning rate: 0.001\n",
    "- Batch normalization: True\n",
    "- Batch size: 64"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "76fbad97adfd37f1"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "model_12, history_12 = compile_fit_model(\n",
    "    train_ds, validation_ds, learning_rate=0.001, batch_normalization=True, batch_size=64\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2024-05-24T14:16:36.022393Z"
    }
   },
   "id": "b8c1e32665cee72a",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "models = [model_1, model_2, model_3, model_4, model_5, model_6, model_7, model_8, model_9, model_10, model_11, model_12]\n",
    "histories = [history_1, history_2, history_3, history_4, history_5, history_6, history_7, history_8, history_9,\n",
    "             history_10, history_11, history_12]"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "75c52dbbe5fbcad8",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def plot_losses_and_metrics(history, title):\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "    # Plot losses\n",
    "    axs[0].plot(history.history['loss'], label=f\"train {history.history['loss'][-1]:.2f}\", color=\"#003B80\",\n",
    "                linestyle=\"dotted\")\n",
    "    axs[0].plot(history.history['val_loss'], label=f\"validation {history.history['val_loss'][-1]:.2f}\", color=\"#003B80\")\n",
    "\n",
    "    axs[0].set_title('Loss', color='#003B80', fontsize=14)\n",
    "\n",
    "    axs[0].set_xlabel('Epoch', color='#003B80')\n",
    "    axs[0].xaxis.set_major_locator(MultipleLocator(1))\n",
    "\n",
    "    axs[0].set_ylabel('Loss', color='#003B80')\n",
    "    axs[0].set_ylim(ymin=0, ymax=1.1)\n",
    "    axs[0].yaxis.set_major_locator(MultipleLocator(0.1))\n",
    "\n",
    "    axs[0].set_facecolor(\"#E3F7FA\")\n",
    "    axs[0].grid(visible=True, which='major', axis='both', color='white')\n",
    "    axs[0].set_axisbelow(True)\n",
    "    axs[0].legend()\n",
    "\n",
    "    # Plot metrics (sensitivity, specificity)\n",
    "    specificity = np.array(history.history['tn']) / (np.array(history.history['tn']) + np.array(history.history['fp']))\n",
    "    val_specificity = np.array(history.history['val_tn']) / (\n",
    "            np.array(history.history['val_tn']) + np.array(history.history['val_fp']))\n",
    "\n",
    "    axs[1].plot(history.history['recall'], label=f\"sensitivity train {history.history['recall'][-1]:.2f}\",\n",
    "                color=\"#003B80\",\n",
    "                linestyle=\"dotted\")\n",
    "    axs[1].plot(history.history['val_recall'], label=f\"sensitivity validation {history.history['val_recall'][-1]:.2f}\",\n",
    "                color=\"#003B80\")\n",
    "    axs[1].plot(specificity, label=f\"specificity train {specificity[-1]:.2f}\", color=\"#FFA500\", linestyle=\"dotted\")\n",
    "    axs[1].plot(val_specificity, label=f\"specificity validation {val_specificity[-1]:.2f}\", color=\"#FFA500\")\n",
    "\n",
    "    axs[1].set_title('Metrics', color='#003B80', fontsize=14)\n",
    "\n",
    "    axs[1].set_xlabel('Epoch', color='#003B80')\n",
    "    axs[1].xaxis.set_major_locator(MultipleLocator(1))\n",
    "\n",
    "    axs[1].set_ylabel('Metric value', color='#003B80')\n",
    "    axs[1].set_ylim(ymin=0, ymax=1.1)\n",
    "    axs[1].yaxis.set_major_locator(MultipleLocator(0.1))\n",
    "\n",
    "    axs[1].set_facecolor(\"#E3F7FA\")\n",
    "    axs[1].grid(visible=True, which='major', axis='both', color='white')\n",
    "    axs[1].set_axisbelow(True)\n",
    "    axs[1].legend()\n",
    "\n",
    "    fig.suptitle(title, fontsize=18, color='#003B80')\n",
    "    return fig\n"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "b1205b6cd8692471",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "for idx, history in enumerate(histories):\n",
    "    fig = plot_losses_and_metrics(history, f'Model {idx + 1}')"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "6d862e1780def26d",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "In a graph, shows for all models and the best epoch; the sensitivity metric with the confidence interval."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6c92018384fd8321"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def plot_intervals(axes, intervalos, title, xlabel, ylabels):\n",
    "    for index, (inferior, superior) in enumerate(intervalos):\n",
    "        position = len(intervalos) - index - 1\n",
    "        average = ((superior - inferior) / 2) + inferior\n",
    "        axes.plot([inferior, superior], [position, position], marker='|', markersize=10, linestyle='-')\n",
    "        axes.scatter(average, position)\n",
    "\n",
    "    axes.set_yticks(np.arange(len(ylabels)))\n",
    "    axes.set_yticklabels(ylabels[::-1])\n",
    "    axes.set_xlabel(xlabel)\n",
    "    axes.set_title(title)\n",
    "\n",
    "    axes.set_facecolor(\"#F0F7FF\")\n",
    "    axes.grid(visible=True, which='major', axis='both', color=\"#FFFFFF\", linewidth=1)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "91567d3f16107e28",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "figure = plt.figure(figsize=(10, 10))\n",
    "axes = figure.add_subplot()\n",
    "\n",
    "confidence_intervals = []\n",
    "for history in histories:\n",
    "    tp = np.array(history.history['tp'])\n",
    "    fn = np.array(history.history['fn'])\n",
    "    # FIXME: All validation metrics cover the whole range\n",
    "    # tp = np.array(history.history['val_tp'])\n",
    "    # fn = np.array(history.history['val_fn'])\n",
    "    specificity = tp / (tp + fn)\n",
    "    best_epoch = np.argmax(specificity)\n",
    "    lower, upper = proportion_confint(tp[best_epoch], tp[best_epoch] + fn[best_epoch], alpha=0.05, method='jeffreys')\n",
    "    confidence_intervals.append((lower, upper))\n",
    "\n",
    "y_labels = [f'Model {i + 1}' for i in range(12)]\n",
    "\n",
    "plot_intervals(axes, confidence_intervals, 'Sensitivity comparison', 'Sensitivity', y_labels)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "29d2b7ff54dba8ea",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "figure = plt.figure(figsize=(10, 10))\n",
    "axes = figure.add_subplot()\n",
    "\n",
    "confidence_intervals = []\n",
    "for history in histories:\n",
    "    tn = np.array(history.history['val_tn'])\n",
    "    fp = np.array(history.history['val_fp'])\n",
    "    specificity = tn / (tn + fp)\n",
    "    best_epoch = np.argmax(specificity)\n",
    "    lower, upper = proportion_confint(tn[best_epoch], tn[best_epoch] + fp[best_epoch], alpha=0.05, method='jeffreys')\n",
    "    confidence_intervals.append((lower, upper))\n",
    "\n",
    "y_labels = [f'Model {i + 1}' for i in range(12)]\n",
    "\n",
    "plot_intervals(axes, confidence_intervals, 'Specificity comparison', 'Specificity', y_labels)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "bfd5abdf87c2db5",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Model choice"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "edce12a536ec513d"
  },
  {
   "cell_type": "markdown",
   "source": [
    "In order to choose the best model, we will focus on the sensitivity metric. The main reasons to choose this method are:\n",
    "- The metric is independent of the prevalence and, for our problem, this is specially important since the train dataset is unbalanced towards more adult picture but in production, it will be unbalanced towards more minor pictures.\n",
    "- It is important to maximize the number of true positives to avoid minors appear in the import. Even if this could cause more false negatives, it will always be better to pixelate out an adult from the picture rather than not pixelating a minor.\n",
    "\n",
    "The model that gives the best results is model 6."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d9f41d20350c6181"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "best_model = model_6"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "cc8aaaebf739469b",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Train the model more epochs, until there is no improvement in the validation loss"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4701d21155d787d3"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=5,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "best_model_history = best_model.fit(train_ds, validation_data=validation_ds, epochs=100, batch_size=32, verbose=False,\n",
    "                                    callbacks=[early_stopping])"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "ccee1496f053aa88",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "thresholds = np.linspace(0, 1, 100)\n",
    "\n",
    "sensitivities = []\n",
    "specificities = []\n",
    "\n",
    "y_scores = best_model.predict(validation_ds, verbose=False)\n",
    "y_true = np.concatenate([y for x, y in validation_ds], axis=0)\n",
    "\n",
    "for threshold in thresholds:\n",
    "    y_pred = y_scores > threshold\n",
    "\n",
    "    tp = np.sum(y_pred & y_true)\n",
    "    fn = np.sum(~y_pred & y_true)\n",
    "    tn = np.sum(~y_pred & ~y_true)\n",
    "    fp = np.sum(y_pred & ~y_true)\n",
    "\n",
    "    sensitivity = tp / (tp + fn)\n",
    "    specificity = tn / (tn + fp)\n",
    "\n",
    "    sensitivities.append(sensitivity)\n",
    "    specificities.append(specificity)\n"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "965e8f03d9aac5ba",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def plot_threshold_vs_metrics(thresholds, sensitivities, specificities):\n",
    "    fig, ax = plt.subplots(figsize=(10, 5))\n",
    "\n",
    "    ax.plot(thresholds, sensitivities, label='Sensitivity', color='#003B80')\n",
    "    ax.plot(thresholds, specificities, label='Specificity', color='#FFA500')\n",
    "\n",
    "    ax.set_title('Threshold vs Sensitivity and Specificity', fontsize=14, color='#003B80')\n",
    "    ax.set_xlabel('Threshold', color='#003B80')\n",
    "    ax.set_ylabel('Metric value', color='#003B80')\n",
    "\n",
    "    ax.set_facecolor(\"#E3F7FA\")\n",
    "    ax.grid(visible=True, which='major', axis='both', color='white')\n",
    "    ax.set_axisbelow(True)\n",
    "    ax.legend()\n",
    "\n",
    "    return fig"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "b0fcc08419196a7",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "_ = plot_losses_and_metrics(best_model_history, 'Best model (model 6)')"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "4844df73d813141a",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "_ = plot_threshold_vs_metrics(thresholds, sensitivities, specificities)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "43e4e1e8eb30e971",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "The best threshold for our problem will be around 0.1, as explained above, we want to maximize the number of true positives so there are no minors in the final picture. This threshold has almost the highest sensitivity, and even if the specificity is rather low, it is not our main goal."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "22c04074e03bcaa3"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "best_threshold_model = 0.1\n",
    "\n",
    "y_scores = best_model.predict(validation_ds, verbose=False)\n",
    "y_pred = y_scores > best_threshold_model\n",
    "\n",
    "tp = np.sum(y_pred & y_true)\n",
    "fn = np.sum(~y_pred & y_true)\n",
    "tn = np.sum(~y_pred & ~y_true)\n",
    "fp = np.sum(y_pred & ~y_true)\n",
    "\n",
    "best_sensitivity_interval = proportion_confint(tp, tp + fn, alpha=0.05, method='jeffreys')\n",
    "best_specificity_interval = proportion_confint(tn, tn + fp, alpha=0.05, method='jeffreys')"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "c9865c371d5eea6c",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now you are going to re-create the model using knowledge transfer. For this you use the pre-trained MobileNetV2 model. To perform knowledge transfer, you have to perform the phases of both feature extraction and fine tuning. "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "824c9119ed2d72b9"
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Feature extraction**"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bcc666921ee90eeb"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "base_model = MobileNetV2(include_top=False, weights='imagenet', input_shape=(IMG_SIZE))\n",
    "base_model.trainable = False\n",
    "\n",
    "preprocess_input = tf.keras.applications.mobilenet_v2.preprocess_input\n",
    "\n",
    "input = layers.Input(shape=IMG_SIZE)\n",
    "\n",
    "x = preprocess_input(input)\n",
    "x = base_model(x, training=False)\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(32, activation='relu')(x)\n",
    "output = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "model_transfer_knowledge = Model(inputs=[input], outputs=[output])\n",
    "\n",
    "model_transfer_knowledge.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=[\n",
    "        'recall',\n",
    "        TruePositives(name='tp'),\n",
    "        TrueNegatives(name='tn'),\n",
    "        FalsePositives(name='fp'),\n",
    "        FalseNegatives(name='fn'),\n",
    "    ]\n",
    ")\n",
    "\n",
    "history_transfer_knowledge = model_transfer_knowledge.fit(train_ds, validation_data=validation_ds, epochs=5,\n",
    "                                                          batch_size=32, verbose=False)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "118d5c3ffc48b6b8",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Fine tuning**"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9745b995fb758c7d"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# TODO: probar a hacer el fine tuning entero\n",
    "base_model.trainable = True\n",
    "\n",
    "fine_tuning_layer = 100\n",
    "for layer in base_model.layers[:fine_tuning_layer]:\n",
    "    layer.trainable = False\n",
    "\n",
    "model_transfer_knowledge.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-5),\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=[\n",
    "        'recall',\n",
    "        TruePositives(name='tp'),\n",
    "        TrueNegatives(name='tn'),\n",
    "        FalsePositives(name='fp'),\n",
    "        FalseNegatives(name='fn'),\n",
    "    ]\n",
    ")\n",
    "\n",
    "history_fine_tuning = model_transfer_knowledge.fit(train_ds, validation_data=validation_ds, epochs=100, batch_size=32,\n",
    "                                                   verbose=False, callbacks=[early_stopping])"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "add08c8ec823cb5f",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "_ = plot_losses_and_metrics(history_fine_tuning, 'MobileNet with fine tuning')"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "1c524988aa2f3fab",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "thresholds_mobilenet = np.linspace(0, 1, 100)\n",
    "\n",
    "sensitivities_mobilenet = []\n",
    "specificities_mobilenet = []\n",
    "\n",
    "y_scores_mobilenet = model_transfer_knowledge.predict(validation_ds, verbose=False)\n",
    "y_true = np.concatenate([y for x, y in validation_ds], axis=0)\n",
    "\n",
    "for threshold in thresholds_mobilenet:\n",
    "    y_pred = y_scores_mobilenet > threshold\n",
    "\n",
    "    tp = np.sum(y_pred & y_true)\n",
    "    fn = np.sum(~y_pred & y_true)\n",
    "    tn = np.sum(~y_pred & ~y_true)\n",
    "    fp = np.sum(y_pred & ~y_true)\n",
    "\n",
    "    sensitivity = tp / (tp + fn)\n",
    "    specificity = tn / (tn + fp)\n",
    "\n",
    "    sensitivities_mobilenet.append(sensitivity)\n",
    "    specificities_mobilenet.append(specificity)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "6d4c21d7e45b62a4",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "_ = plot_threshold_vs_metrics(thresholds_mobilenet, sensitivities_mobilenet, specificities_mobilenet)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "42e30a7911b30937",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "The best threshold for our problem will be around 0.3 for the reasons explained above in the previous model."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ca8e4a6ce4b5a25"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "best_threshold_mobilenet_model = 0.3\n",
    "\n",
    "y_pred = y_scores_mobilenet > best_threshold_mobilenet_model\n",
    "\n",
    "tp = np.sum(y_pred & y_true)\n",
    "fn = np.sum(~y_pred & y_true)\n",
    "tn = np.sum(~y_pred & ~y_true)\n",
    "fp = np.sum(y_pred & ~y_true)\n",
    "\n",
    "best_mobilenet_sensitivity_interval = proportion_confint(tp, tp + fn, alpha=0.05, method='jeffreys')\n",
    "best_mobilenet_specificity_interval = proportion_confint(tn, tn + fp, alpha=0.05, method='jeffreys')"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "5050bb0c2dc3643e",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "figure = plt.figure(figsize=(5, 2))\n",
    "axes = figure.add_subplot()\n",
    "\n",
    "plot_intervals(\n",
    "    axes,\n",
    "    [best_sensitivity_interval, best_mobilenet_sensitivity_interval],\n",
    "    'Sensitivity comparison',\n",
    "    'Sensitivity',\n",
    "    ['My model', 'MobileNet']\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "7ff13d469b107b5a",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "figure = plt.figure(figsize=(5, 2))\n",
    "axes = figure.add_subplot()\n",
    "\n",
    "plot_intervals(\n",
    "    axes,\n",
    "    [best_specificity_interval, best_mobilenet_specificity_interval],\n",
    "    'Specificity comparison',\n",
    "    'Specificity',\n",
    "    ['My model', 'MobileNetV2']\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "612b502f6f513e6a",
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
